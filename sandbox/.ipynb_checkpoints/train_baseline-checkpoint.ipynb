{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "from os import listdir,mkdir,rmdir\n",
    "from os.path import join,isdir,isfile\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage.morphology import binary_dilation,binary_erosion\n",
    "from skimage import exposure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms,utils\n",
    "from torchvision.transforms import functional as func\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.models.segmentation.fcn import FCNHead\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 16,9\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SWITCHES\n",
    "\n",
    "path_tr = \"/home/darvin/Data/cellSegmentation/train_combine\"\n",
    "path_va = \"/home/darvin/Data/cellSegmentation/test\"\n",
    "path_te = \"/home/darvin/Data/cellSegmentation/test\"\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLabV3(\n",
      "  (backbone): IntermediateLayerGetter(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): DeepLabHead(\n",
      "    (0): ASPP(\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): ASPPConv(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (4): ASPPPooling(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (project): Sequential(\n",
      "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "\n",
    "#model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "#model.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#model.classifier = DeepLabHead(2048, num_classes)\n",
    "#set_parameter_requires_grad(model, feature_extract)\n",
    "\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False)\n",
    "model.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.classifier = DeepLabHead(2048, num_classes)\n",
    "set_parameter_requires_grad(model, feature_extract)\n",
    "\n",
    "#model = torchvision.models.segmentation.fcn_resnet50(pretrained=False)\n",
    "#model.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#model.classifier = FCNHead(2048, num_classes)\n",
    "#set_parameter_requires_grad(model, feature_extract)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation Classes\n",
    "\n",
    "class RandomRotate(object):\n",
    "    def __call__(self, sample):\n",
    "        X,Y = sample['X'],sample['Y']\n",
    "        rotnum = np.random.choice(4)\n",
    "        for ii in range(X.shape[0]):\n",
    "            X[ii,:,:] = np.rot90(X[ii,:,:],k=rotnum,axes=(0,1))\n",
    "        Y[:,:] = np.rot90(Y,k=rotnum,axes=(0,1))\n",
    "        return {'X':X, 'Y':Y}\n",
    "    \n",
    "class RandomShift(object):\n",
    "    def __init__(self, max_shift=32):\n",
    "        self.max_shift = int(max_shift)\n",
    "    def __call__(self, sample):\n",
    "        X,Y = sample['X'],sample['Y']\n",
    "        h,w = X.shape[1:]\n",
    "        X_shift = np.zeros((X.shape[0], X.shape[1]+2*self.max_shift, X.shape[2]+2*self.max_shift))\n",
    "        for ii in range(X.shape[0]):\n",
    "            X_shift[ii,:,:] = np.pad(X[ii,:,:], self.max_shift, mode='constant')\n",
    "        Y_shift = np.pad(Y, self.max_shift, mode='constant')\n",
    "        top     = np.random.randint(0, 2*self.max_shift)\n",
    "        left    = np.random.randint(0, 2*self.max_shift)\n",
    "        X[:,:,:] = X_shift[:,top:(top+h), left:(left+w)]\n",
    "        Y[:,:]   = Y_shift[top:(top+h), left:(left+w)]\n",
    "        return {'X':X, 'Y':Y}\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __init__(self, flip_prob=0.5):\n",
    "        self.flip_prob = flip_prob\n",
    "    def __call__(self, sample):\n",
    "        X,Y = sample['X'],sample['Y']\n",
    "        if np.random.rand() > self.flip_prob:\n",
    "            X[:,:,:] = X[:,:,::-1]\n",
    "            Y[:,:]   = Y[:,::-1]\n",
    "        return {'X':X, 'Y':Y}\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        X,Y = sample['X'], sample['Y']\n",
    "        return {'X': torch.from_numpy(X).float(), 'Y': torch.from_numpy(Y).long()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cellSegmentationDataset(Dataset):\n",
    "    def __init__(self, path_imgs, path_segs, transform=None):\n",
    "        self.path_imgs = path_imgs\n",
    "        self.path_segs = path_segs\n",
    "        self.transform = transform\n",
    "        self.list_imgs = sorted(listdir(path_imgs))\n",
    "    def __len__(self):\n",
    "        return len(self.list_imgs)\n",
    "    def __getitem__(self,idx):\n",
    "        img = cv2.imread(join(self.path_imgs, self.list_imgs[idx]))[:,:,0]\n",
    "        img = img.astype(np.float32) / 255\n",
    "        #img = np.transpose(img, (2,0,1))\n",
    "        img = img.reshape([1,img.shape[0],img.shape[1]])\n",
    "        \n",
    "        seg = cv2.imread(join(self.path_segs, self.list_imgs[idx]))\n",
    "        seg = (seg[:,:,0] > 0) + 0\n",
    "        \n",
    "        sample = {'X': img, 'Y': seg}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = cellSegmentationDataset(join(path_tr, 'img'), join(path_tr,'seg'),\n",
    "                                  transform=transforms.Compose([RandomRotate(),RandomFlip(),RandomShift(),ToTensor()]))\n",
    "data_va = cellSegmentationDataset(join(path_va, 'img'), join(path_va,'seg'),\n",
    "                                  transform=transforms.Compose([ToTensor()]))\n",
    "data_te = cellSegmentationDataset(join(path_te, 'img'), join(path_te,'seg'),\n",
    "                                  transform=transforms.Compose([ToTensor()]))\n",
    "\n",
    "loader_tr = DataLoader(data_tr, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "loader_va = DataLoader(data_va, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "loader_te = DataLoader(data_te, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "dataloaders_tr = {'train': loader_tr, 'val': loader_va}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model to GPU\n",
    "model = model.cuda()\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=0.001, weight_decay=0.001)\n",
    "#optimizer = optim.SGD(params_to_update, lr=0.0001, momentum=0.9, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    tr_iou_history = []\n",
    "    tr_loss_history = []\n",
    "    val_iou_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_iou = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_iou = 0.0\n",
    "            counter = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            optimizer.zero_grad()\n",
    "            for sample_batch in dataloaders[phase]:\n",
    "                X = sample_batch['X'].cuda()\n",
    "                Y = sample_batch['Y'].cuda()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    output = model(X)\n",
    "                    loss = criterion(output['out'],Y)\n",
    "                    \n",
    "                    Y_copy = Y.detach().cpu().numpy()\n",
    "                    weight = np.ones_like(Y_copy)\n",
    "                    for ii in range(Y.size(0)):\n",
    "                        Y_slice = Y_copy[ii,:,:]\n",
    "                        boundary = (binary_dilation(Y_slice > 0) + 0) - (binary_erosion(Y_slice > 0) + 0)\n",
    "                        weight[ii,:,:] += boundary * 9\n",
    "                    loss = torch.mean(loss * torch.from_numpy(weight).float().cuda())\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        counter += 1\n",
    "                        if counter%4 == 0:\n",
    "                            optimizer.step()\n",
    "                            optimizer.zero_grad()\n",
    "                \n",
    "                running_loss += loss.item() * X.size(0)\n",
    "                pred = torch.argmax(output['out'],dim=1)\n",
    "                running_iou += 2 * torch.sum(pred.float() * Y.float()) * X.size(0) / (torch.sum(pred.float()) + torch.sum(Y.float()))\n",
    "            if counter%4 != 0 and phase == 'train':\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_iou = running_iou / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} IOU: {:.4f}'.format(phase, epoch_loss, epoch_iou))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_iou > best_iou:\n",
    "                    best_iou = epoch_iou\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(model.state_dict(), '/home/darvin/Models/cellSegmentation.pth')\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_iou_history.append(epoch_iou)\n",
    "            else:\n",
    "                tr_iou_history.append(epoch_iou)\n",
    "                tr_loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val IOU: {:4f}'.format(best_iou))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, [val_iou_history,val_loss_history,tr_iou_history,tr_loss_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the loss fxn\n",
    "#criterion = nn.CrossEntropyLoss(torch.Tensor([1,3]).cuda())\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# Train and evaluate\n",
    "model, history = train_model(model, dataloaders_tr, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state_dict = torch.load('/home/darvin/Models/cellSegmentation.pth')\n",
    "model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model, path_img):\n",
    "    model = model.cuda().eval()\n",
    "    img = cv2.imread(path_img)[:,:,0]\n",
    "    img = img.astype(np.float32) / 255\n",
    "    seg = F.softmax(model(torch.from_numpy(img.reshape([1,img.shape[0],img.shape[1]])).float().unsqueeze(0).cuda())['out'],dim=1)\n",
    "    seg = seg[0,:,:,:].detach().cpu().numpy()\n",
    "    return img,seg[1,:,:]\n",
    "\n",
    "def calculate_ious(seg,gt,ts):\n",
    "    ious = np.zeros_like(ts)\n",
    "    for ii,t in enumerate(ts):\n",
    "        intersection = np.sum((seg > t) * (gt > 0))\n",
    "        union = np.sum(((seg > t) + (gt > 0)) > 0)\n",
    "        ious[ii] = float(intersection) / float(union) + float(512**2 - union) / float(512**2 - intersection)\n",
    "    return ious / 2\n",
    "\n",
    "def save_visualization(model,path_img,path_gt,path_save):\n",
    "    model = model.cuda().eval()\n",
    "    img = cv2.imread(path_img).astype(np.float32) / 255\n",
    "    \n",
    "    vis = np.zeros_like(img)\n",
    "    gt = (cv2.imread(path_gt)[:,:,0] > 0) + 0\n",
    "    \n",
    "    img = img[:,:,0]\n",
    "    seg = F.softmax(model(torch.from_numpy(img.reshape([1,img.shape[0],img.shape[1]])).float().unsqueeze(0).cuda())['out'],dim=1)\n",
    "    seg = seg[0,:,:,:].detach().cpu().numpy()\n",
    "    \n",
    "    intersection = np.sum((seg[1,:,:] > 0.5) * (gt > 0))\n",
    "    union = np.sum(((seg[1,:,:] > 0.5) + (gt > 0)) > 0)\n",
    "    iou = float(intersection) / float(union)\n",
    "    \n",
    "    for ii in range(3):\n",
    "        vis[:,:,ii] += img * 0.8\n",
    "    vis[:,:,1] += gt * 0.5\n",
    "    vis[:,:,0] += ((seg[1,:,:] > 0.5) + 0) * 0.5\n",
    "    vis[:,:,2] += ((seg[1,:,:] > 0.5) + 0) * 0.5\n",
    "    vis = np.clip(vis,0,1)\n",
    "    vis = cv2.putText((255*vis).astype(np.uint8),'IoU: ' + str(iou),org=(10,30), fontFace = cv2.FONT_HERSHEY_SIMPLEX ,fontScale=1,color=(0,255,255), thickness=2)\n",
    "    cv2.imwrite(path_save,vis)\n",
    "    \n",
    "def normalize_img(img):\n",
    "    img -= img.min()\n",
    "    img /= (img.max() + 1e-6)\n",
    "    return img\n",
    "\n",
    "def preprocess_img(path_img):\n",
    "    img = np.array(Image.open(path_img)).astype(np.float32)\n",
    "    img = normalize_img(img)\n",
    "    img = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    img = cv2.resize(img,(512,512))\n",
    "    return img\n",
    "\n",
    "def do_full_inference(model,path_img,path_save=None):\n",
    "    model = model.cuda().eval()\n",
    "    \n",
    "    img = preprocess_img(path_img)\n",
    "    if len(img.shape) == 3:\n",
    "        img = img[:,:,0]\n",
    "    \n",
    "    seg = F.softmax(model(torch.from_numpy(img.reshape([1,img.shape[0],img.shape[1]])).float().unsqueeze(0).cuda())['out'],dim=1)\n",
    "    seg = seg[0,:,:,:].detach().cpu().numpy()\n",
    "    \n",
    "    if path_save:\n",
    "        cv2.imwrite(path_save,(255*seg[1,:,:]).astype(np.float32))\n",
    "        \n",
    "    return img,seg[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 30\n",
    "\n",
    "path_testing = '/home/darvin/Data/cellSegmentation/test/'\n",
    "list_imgs = sorted(listdir(join(path_testing,'img')))\n",
    "path_img = join(path_testing,'img',list_imgs[ind])\n",
    "path_gt = join(path_testing,'seg',list_imgs[ind])\n",
    "img,seg = apply_model(model,path_img)\n",
    "gt = cv2.imread(path_gt)[:,:,0]\n",
    "\n",
    "fig,ax = plt.subplots(1,3)\n",
    "ax[0].imshow(img,cmap='bone')\n",
    "ax[1].imshow(seg>0.5,cmap='bone')\n",
    "ax[2].imshow(gt,cmap='bone')\n",
    "\n",
    "intersection = np.sum((seg > 0.5) * (gt > 0))\n",
    "union = np.sum(((seg > 0.5) + (gt > 0)) > 0)\n",
    "iou1 = float(intersection) / float(union)\n",
    "intersection = np.sum((seg < 0.5) * (gt == 0))\n",
    "union = np.sum(((seg < 0.5) + (gt == 0)) > 0)\n",
    "iou2 = float(intersection) / float(union)\n",
    "ax[1].set_title((iou1+iou2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].imshow((seg > 0.5) * (gt > 0))\n",
    "ax[1].imshow(((seg > 0.5) + (gt > 0)) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.arange(0.01,1.0,0.01)\n",
    "ious = np.zeros_like(ts)\n",
    "path_va = '/home/darvin/Data/cellSegmentation/test/'\n",
    "list_imgs = sorted(listdir(join(path_va,'img')))\n",
    "for name_img in list_imgs:\n",
    "    path_img = join(path_va,'img',name_img)\n",
    "    path_gt = join(path_va,'seg',name_img)\n",
    "    img,seg = apply_model(model,path_img)\n",
    "    gt = cv2.imread(path_gt)[:,:,0]\n",
    "    ious += calculate_ious(seg,gt,ts) / len(list_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts,ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[np.argmax(ious)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_va = '/home/darvin/Data/cellSegmentation/test/'\n",
    "path_save = join(path_va, 'vis')\n",
    "if not isdir(path_save):\n",
    "    mkdir(path_save)\n",
    "list_imgs = sorted(listdir(join(path_va,'img')))\n",
    "for name_img in list_imgs:\n",
    "    path_img = join(path_va,'img',name_img)\n",
    "    path_gt = join(path_va,'seg',name_img)\n",
    "    save_visualization(model,path_img,path_gt,join(path_save,name_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_array(path_img,path_seg):\n",
    "    img = np.array(Image.open(path_img)).astype(np.float32)\n",
    "    seg = np.array(Image.open(path_seg)).astype(np.float32)\n",
    "    \n",
    "    img = normalize_img(img)\n",
    "    #seg = (seg > 0)\n",
    "    img = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    \n",
    "    img = cv2.resize(img,(512,512))\n",
    "    seg = cv2.resize(seg,(512,512))\n",
    "    seg = (seg > 0)\n",
    "    \n",
    "    img = (255*img).astype(np.uint8)\n",
    "    seg = (255*seg).astype(np.uint8)\n",
    "    \n",
    "    return img,seg\n",
    "\n",
    "def read_img(path_img):\n",
    "    img = np.array(Image.open(path_img)).astype(np.float32)\n",
    "    img = normalize_img(img)\n",
    "    if len(img.shape) == 3:\n",
    "        img = img[:,:,0]\n",
    "    img = cv2.resize(img,(512,512))\n",
    "    return img\n",
    "\n",
    "def calculate_iou(seg,gt):\n",
    "    intersection = np.sum((seg> 0.5) * (gt > 0))\n",
    "    union = np.sum(((seg > 0.5) + (gt > 0)) > 0)\n",
    "    iou = float(intersection) / float(union)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imgs = \"/home/darvin/Data/cellSegmentation/rawDataFromHumanExperts\"\n",
    "path_save = \"/home/darvin/Data/cellSegmentation/humanVisualization\"\n",
    "list_imgs = sorted(listdir(path_imgs))\n",
    "\n",
    "dict_hum2mac = {}\n",
    "\n",
    "for name_img in list_imgs:\n",
    "    parts = name_img.split('_')\n",
    "    if parts[0] != 'DIC':\n",
    "        continue\n",
    "    name_root = '_'+'_'.join(parts[1:])\n",
    "    path_img = join(path_imgs, 'DIC' + name_root)\n",
    "    path_seg = join(path_imgs, 'Nul' + name_root)\n",
    "    for name_human in ['James', 'LiAng', 'Sheng', 'Yitong']:\n",
    "        path_hum = join(path_imgs, name_human + name_root)\n",
    "        if isfile(path_hum):\n",
    "            break\n",
    "    if name_human not in dict_hum2mac:\n",
    "        dict_hum2mac[name_human] = ([],[])\n",
    "    img = read_img(path_img)\n",
    "    gt  = read_img(path_seg)\n",
    "    hum = read_img(path_hum)\n",
    "    _,pred = do_full_inference(model,path_img,path_save=None)\n",
    "    \n",
    "    path_save_img = join(path_save, name_root[1:])\n",
    "    \n",
    "    vis = np.zeros((512,1024,3))\n",
    "    for ii in range(3):\n",
    "        for jj in range(2):\n",
    "            vis[:,(jj*512):(jj*512+512),ii] += img * 0.8\n",
    "            if ii == 1:\n",
    "                vis[:,(jj*512):(jj*512+512),ii] += gt * 0.5\n",
    "    vis[:,512:1024,0] += hum * 0.5\n",
    "    vis[:,:512,2] += ((pred > 0.5) + 0) * 0.5\n",
    "    vis = np.clip(vis,0,1)\n",
    "    \n",
    "    iou_machine = calculate_iou(pred,gt)\n",
    "    iou_human = calculate_iou(hum,gt)\n",
    "    dict_hum2mac[name_human][0].append(iou_human)\n",
    "    dict_hum2mac[name_human][1].append(iou_machine)\n",
    "    \n",
    "    \n",
    "    vis = (255*vis).astype(np.uint8)\n",
    "    vis = cv2.putText(vis,'IoU: ' + str(iou_machine),org=(10,30), fontFace = cv2.FONT_HERSHEY_SIMPLEX ,fontScale=1,color=(0,255,255), thickness=2)\n",
    "    vis = cv2.putText(vis,'IoU: ' + str(iou_human),org=(522,30), fontFace = cv2.FONT_HERSHEY_SIMPLEX ,fontScale=1,color=(255,255,0), thickness=2)\n",
    "    vis = cv2.putText(vis, name_human,org=(522,80), fontFace = cv2.FONT_HERSHEY_SIMPLEX ,fontScale=1,color=(255,255,0), thickness=2)\n",
    "    cv2.imwrite(path_save_img,vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_hum2col = {'Yitong':'r', 'Sheng':'g', 'LiAng':'b', 'James':'k'}\n",
    "\n",
    "for name_human in dict_hum2col:\n",
    "    col = dict_hum2col[name_human]\n",
    "    x,y = dict_hum2mac[name_human]\n",
    "    plt.scatter(x,y,c=col)\n",
    "plt.plot([0,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
